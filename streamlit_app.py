import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import pickle
import pandas as pd
from interpret.glassbox import ExplainableBoostingClassifier

# Load the trained EBM model
MODEL_PATH = "models/ebm_model.pkl"

with open(MODEL_PATH, "rb") as file:
    ebm = pickle.load(file)

# Extract expected feature names from the model
feature_names = ebm.term_names_

# Normal ranges for reference
normal_ranges = {
    '–í–æ–∑—Ä–∞—Å—Ç': (0, 100),
    '–û.–∂.,%': (10, 25),
    '–í–∏—Å—Ü.–∂,%': (5, 15),
    '–°–∫–µ–ª–µ—Ç,%': (30, 40),
    '–ö–æ—Å—Ç–∏,–∫–≥': (2, 5),
    '–í–æ–¥–∞,%': (50, 70),
    '–°–û–û–í,–∫–∫–∞–ª': (1500, 3500),
    '–û–ì,—Å–º': (75, 105),
    '–û–¢,—Å–º': (60, 95),
    '–û–ñ,—Å–º': (70, 105),
    '–û–ë,—Å–º': (40, 65),
    '–ò–ú–¢': (18.5, 24.9),
    '–ê–õ–¢': (7, 41),
    '–ê–°–¢': (10, 40),
    '–ì–ì–¢–ü': (10, 70),
    '–©–§': (40, 130),
    '–•–°–æ–±—â.': (0, 5.2),
    '–õ–ü–ù–ü': (0, 3.0),
    '–õ–ü–í–ü': (1.0, 1.5),
    '–¢—Ä–∏–≥–ª–∏—Ü.': (0, 1.7),
    '–ë–∏–ª–∏—Ä.–æ': (0, 1.2),
    '–ë–∏–ª–∏—Ä.–ø—Ä': (0, 0.3),
    '–ì–ª—é–∫–æ–∑–∞': (3.9, 5.5)
}

# Streamlit UI
st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ –ù–ê–ñ–ë–ü", page_icon="üíâ", layout="wide")
st.title("üíâ –ü—Ä–æ–≥–Ω–æ–∑ –ù–ê–ñ–ë–ü")
st.write("–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ù–ê–ñ–ë–ü.")

# User Input Fields
gender = st.radio("**–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–ª:**", ("–ú—É–∂—Å–∫–æ–π", "–ñ–µ–Ω—Å–∫–∏–π"))
gender_value = 0 if gender == "–ú—É–∂—Å–∫–æ–π" else 1

user_inputs = {
    '–ü–æ–ª': gender_value,
    '–í–æ–∑—Ä–∞—Å—Ç': st.number_input("**–í–æ–∑—Ä–∞—Å—Ç**", min_value=0, max_value=100, value=30),
    '–û.–∂.,%': st.number_input("**–û.–∂.,%**", min_value=0.0, max_value=100.0, value=20.0),
    '–í–∏—Å—Ü.–∂,%': st.number_input("**–í–∏—Å—Ü.–∂,%**", min_value=0.0, max_value=100.0, value=5.0),
    '–°–∫–µ–ª–µ—Ç,%': st.number_input("**–°–∫–µ–ª–µ—Ç,%**", min_value=0.0, max_value=100.0, value=40.0),
    '–ö–æ—Å—Ç–∏,–∫–≥': st.number_input("**–ö–æ—Å—Ç–∏,–∫–≥**", min_value=0.0, max_value=20.0, value=3.0),
    '–í–æ–¥–∞,%': st.number_input("**–í–æ–¥–∞,%**", min_value=0.0, max_value=100.0, value=60.0),
    '–°–û–û–í,–∫–∫–∞–ª': st.number_input("**–°–û–û–í,–∫–∫–∞–ª**", min_value=0.0, max_value=5000.0, value=2000.0),
    '–û–ì,—Å–º': st.number_input("**–û–ì,—Å–º**", min_value=0.0, max_value=150.0, value=90.0),
    '–û–¢,—Å–º': st.number_input("**–û–¢,—Å–º**", min_value=0.0, max_value=150.0, value=80.0),
    '–û–ñ,—Å–º': st.number_input("**–û–ñ,—Å–º**", min_value=0.0, max_value=150.0, value=100.0),
    '–û–ë,—Å–º': st.number_input("**–û–ë,—Å–º**", min_value=0.0, max_value=150.0, value=55.0),
    '–ò–ú–¢': st.number_input("**–ò–ú–¢**", min_value=0.0, max_value=100.0, value=24.0),
    '–ê–õ–¢': st.number_input("**–ê–õ–¢**", min_value=0.0, max_value=200.0, value=30.0),
    '–ê–°–¢': st.number_input("**–ê–°–¢**", min_value=0.0, max_value=200.0, value=30.0),
    '–ì–ì–¢–ü': st.number_input("**–ì–ì–¢–ü**", min_value=0.0, max_value=200.0, value=15.0),
}

# Predict probability and classify
if st.button("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ü—Ä–æ–≥–Ω–æ–∑"):
    # Ensure input order matches model's feature order
    input_values = [user_inputs[feat] for feat in feature_names if feat in user_inputs]

    # Convert to NumPy array
    input_array = np.array(input_values).reshape(1, -1)

    # Predict probability
    probability = ebm.predict_proba(input_array)[0][1]
    predicted_class = "–ë–æ–ª–µ–Ω" if probability >= 0.5 else "–ó–¥–æ—Ä–æ–≤"

    st.subheader("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ü—Ä–æ–≥–Ω–æ–∑–∞:**")
    st.write(f"**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å:** {probability:.4f}")
    st.write(f"**–ö–ª–∞—Å—Å:** {predicted_class}")

    if predicted_class == "–ë–æ–ª–µ–Ω":
        st.error("üö® –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≤—ã –±–æ–ª—å–Ω—ã.")
    else:
        st.success("‚úÖ –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≤—ã –∑–¥–æ—Ä–æ–≤—ã.")

    # Normalize user values for comparison
    feature_keys = list(normal_ranges.keys())
    normal_min = [normal_ranges[key][0] for key in feature_keys]
    normal_max = [normal_ranges[key][1] for key in feature_keys]

    def normalize(values, min_vals, max_vals):
        return [(val - min_val) / (max_val - min_val) for val, min_val, max_val in zip(values, min_vals, max_vals)]

    normalized_user_values = normalize(input_values[1:], normal_min, normal_max)

    # Plot comparison graph
    fig, ax = plt.subplots(figsize=(10, 8))

    for i, (min_val, max_val) in enumerate(zip([0] * len(normal_min), [1] * len(normal_max))):
        ax.barh(i, max_val - min_val, left=min_val, color='gray', alpha=0.5, label='–ù–æ—Ä–º–∞' if i == 0 else "", height=0.5)

    for i, value in enumerate(normalized_user_values):
        ax.scatter(value, i, color='blue', s=100, zorder=5, label='–í–∞—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ' if i == 0 else "")

    ax.set_xlim([-0.5, 1.5])
    ax.get_xaxis().set_visible(False)
    ax.set_xlabel('–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (0-1)', fontsize=12, fontweight='bold')
    ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏', fontsize=14, fontweight='bold')

    ax.set_yticks(range(len(feature_keys)))
    ax.set_yticklabels(feature_keys, fontsize=11, fontweight='bold')

    ax.legend(loc='upper left', fontsize=10)
    plt.show()

    st.pyplot(fig)
